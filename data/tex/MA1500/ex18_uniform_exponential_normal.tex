% !TEX root = main.tex
% ex18_uniform_exponential_normal.tex
\begin{exercise}
\begin{questions}
%----------------------------------------
%--------------------
% UNIFORM
% RND 4.2.2
\question
The first bus of the day arrives at a certain stop at 7 a.m., and then at 10 minute intervals until the evening. A girl arrives at the stop at a time which is uniformly distributed between 7.15 a.m. and 7.45 a.m. Find the probability that she waits for a bus for
\ben
\it less than two minutes,
\it more than four minutes.
\een

\begin{answer}
\ben
\it % << (i)
She waits less than two minutes if she arrives during any of the time intervals $(7.18,7.20]$, $(7.28,7.30]$ and $(7.38,7.40]$. The total length of these intervals is $6$ minutes, and there are $30$ minutes between 7.15 a.m. and 7.45 a.m. Since her time of arrival at the bus stop is uniformly distributed between 7.15 a.m. and 7.45 a.m., the probability that she waits for less than two minutes is $6/30 = 0.2$.
\it % << (ii)
She waits more than four minutes if she arrives during any of the intervals $(7.15,7.16]$, $(7.20,7.26]$ and $(7.30,7.36]$. The total length of these intervals is $18$ minutes, so the probability that she waits for more than four minutes is $18/30 = 0.6$.
\een
\end{answer}

%--------------------
% ORDER STATISTICS
% GS 4.2.3
\question
Let $X_1$, $X_2$, $X_3$ and $X_4$ be independent and identically distributed continuous random variables. 
\ben
\it Show that $\prob(X_1 < X_2 < X_3 < X_4) = \frac{1}{24}$.
\it Find $\prob(X_1 > X_2 < X_3 < X_4)$.
\een

\begin{answer}
Since $X_1$, $X_2$, $X_3$ and $X_4$ are independent and identically distributed, every ordering is equally likely. 
\ben
\it There are $4!=24$ possible orderings, so the probability that $X_1 < X_2 < X_3 < X_4$ is equal to $\frac{1}{24}$.
\it There are three possible orderings corresponding to $X_1 > X_2 < X_3 < X_4$:
\[
X_2 < X_1 < X_3 < X_4,\quad X_2 < X_3 < X_1 < X_4 \quad\text{and}\quad X_2 < X_3 < X_4 < X_1.
\]
Each of these has probability $\frac{1}{24}$, so $\prob(X_1 > X_2 < X_3 < X_4) = \frac{3}{24}$.
\een

\end{answer}


%--------------------
% ARRIVALS
% RND 4.2.11
\question
The time $T$ between successive arrivals at a hospital has PDF
\[
f(t) = \begin{cases}
	\lambda e^{-\lambda t} 	& \text{if }\ t\geq 0,\\
	0		  				& \text{otherwise.}		
\end{cases}
\]
Exactly 100 inter-arrival times were measured, and the total was found to be 500 hours.
\ben
\it Estimate the value of $\lambda$.
\it Use this estimate of $\lambda$ to estimate the probabilities $\prob(T\leq 5)$ and $\prob(T\leq 10\,|\, T > 5)$.
\een
\begin{answer}
\ben
\it % << (i)
An estimate of the average inter-arrival time $\expe(T)$ is $\displaystyle\frac{500}{100} = 5$. Since $\expe(T)=\displaystyle\frac{1}{\lambda}$, we take $\displaystyle\frac{1}{5}$ as an estimate of $\lambda$. (This is the so-called \emph{method-of-moments} estimator.)
\it % << (ii)
\begin{align*}
\prob(0<T<5)
	& \approx \int_0^5\frac{1}{5}e^{-t/5}\,dt 
	= \big[-e^{-t/5}\big]_0^5 
	= 1 - e^{-1} 
	= 0.6321. \\
\prob(T<10\,|\,T>5)
	& \approx \frac{\prob(5<T<10)}{\prob(T>5)} 
	= \frac{\big[-e^{-t/5}\big]_5^{10}}{\big[-e^{-t/5}\big]_0^5}
	= 1 - e^{-1} 
	= 0.6321. 
\end{align*}
\een
\end{answer}

%--------------------
% SCALING
% RND 4.2.15
\question
A teacher set and marked an examination, and found that the distribution of marks were (approximately) normally distributed with mean $42$ and standard deviation $14$. The school's policy is to present scaled marks whose distribution is (approximately) normal with mean $50$ and standard deviation $15$. Find the (linear) transformation that the teacher should apply to the raw marks to accomplish this. What is the transformed mark corresponding to a raw mark of $40$?
\begin{answer}
If $X\sim\text{N}(\mu,\sigma^2)$ and $Y=aX+b$ where $a,b\in\R$ are constants, then $Y\sim\text{N}(a\mu+b,a^2\sigma^2)$. To see this,
\[
F(y) = \prob(Y\leq y) 
	 = \prob\left(X\leq\frac{y-b}{a}\right) 
	  = \frac{1}{\sigma\sqrt{2\pi}} \int_{-\infty}^{\frac{y-b}{a}} \exp\left(-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right)\,dx.
\]
Changing the variable of integration from $x$ to $t = ax + b$, this becomes
\[
F(y)  = \frac{1}{|a|\sigma\sqrt{2\pi}} \int_{-\infty}^{y} \exp\left(-\frac{1}{2}\left(\frac{t-(a\mu+b)}{a\sigma}\right)^2\right)\,dt 
\]
which is the distribtion function of a $\text{N}(a\mu+b,a^2\sigma^2)$ random variable.

In this example, $X\sim\text{N}(42,14^2)$ and $Y\sim\text{N}(42a+b,14^2a^2)$, so we need to find $a$ and $b$ such that
\[
42a + b = 50 \quad\text{and}\quad 14^2a^2 = 15^2.
\]
Solving these equations, we obtain the solutions
\[
\left(a = \frac{15}{14},\ b=5\right) \quad\text{and}\quad \left(a = -\frac{15}{14},\ b=95\right). 
\]
The transformation $Y=-\displaystyle\frac{15}{14}X + 95$ transforms the low marks to high marks (and vice versa); the required transformation is 
\[
Y=\displaystyle\frac{15}{14}X + 5.
\]
If the raw mark is $X=40$, the transformed mark is $Y = 48$ (rounded to the nearest integer).
\end{answer}

%--------------------
% MAX AND MIN
% GS 4.2.2
\question
Let $X_1$ and $X_2$ be independent and identically distributed continuous random variables, let $F(x)$ denote their common CDF, and let $f(x)$ denote their common PDF. 
\ben
\it Show that the CDF and PDF of $V=\max\{X_1,X_2\}$ are $F_V(v)=F(v)^2$ and $f_V(v) = 2F(v)f(v)$ respectively.
\it Find the CDF and PDF of $U=\min\{X_1,X_2\}$.
\een
\begin{answer}
\ben
\it % << (i)
$V=\max\{X_1,X_2\}\leq v$ if and only if $X_1\leq v$ and $X_2\leq v$, so by independence,
\begin{align*}
F_V(v) 
	& = \prob(V\leq v) = \prob\big(\max\{X_1,X_2\}\leq v\big) \\
	& = \prob(X_1\leq v,X_2\leq v) \\
	& = \prob(X_1\leq v)\prob(X_2\leq v) \\
	& = F(v)^2.
\end{align*}
Taking the derivative with respect to $v$ (using the chain rule),
\[
f_V(v) = \frac{d}{dv}F_V(v) = \frac{d}{dv}\big(F(v)^2\big) =2F(v)f(v).
\]
\it % << (ii)
$U=\min\{X_1,X_2\}>u$ if and only if $X_1> v$ and $X_2> v$, so by independence,
\begin{align*}
F_U(u) 
	& = 1- \prob(U > u) = 1-\prob\big(\min\{X_1,X_2\} > u\big) \\
	& = 1-\prob(X_1 > u, X_2 > u) \\
	& = 1-\prob(X_1 > u)\prob(X_2 > u) \\
	& = 1-\big(1-F(u)\big)^2.
\end{align*}
%so $F_U(u) = \prob(U\leq u) = 1 - \prob(U > u) = 1 - \big(1-F(u)\big)^2$. 

Taking the derivative with respect to $u$,
\[
f_U(u) = \frac{d}{du}F_U(u) = \frac{d}{du}\Big(1-\big(1-F(u)\big)^2\Big) = 2\big(1-F(u)\big)f(u).
\]
\een
\end{answer}

%--------------------
% EXPECTATION IN TERMS OF COMPLEMENTARY CDF
\question
Let $X:\Omega\to\R $ be a continuous random variable with CDF $F(x)$, and suppose that $X$ is \emph{non-negative} in the sense that $X(\omega)\geq 0$ for all $\omega\in\Omega$. Show that 
\[
\expe(X) = \int_{0}^{\infty}\big(1-F(x)\big)\,dx
\]
\begin{answer}
\begin{align*}
\int_0^\infty 1 - F(x) \,dx 
	& = \int_{0}^{\infty} \prob(X > x)\,dx \\
	& = \int_{0}^{\infty}\left(\int_{x}^{\infty} f(t)\,dt\right)\,dx \\
	& = \int_{0}^{\infty}\left(\int_{0}^{t} f(t)\,dx\right)\,dt \\
	& = \int_{0}^{\infty} t f(t)\,dt \\
	& = \expe(X)
\end{align*}
\end{answer}

%--------------------
% MEMORYLESS (EXP)
\question 
Let $X$ have exponential distribution with (rate) parameter $\lambda$. The CDF of $X$ is as follows:
\[
F(x) = \begin{cases}
	1 - e^{-\lambda x}	& x \geq 0, \\
	0					& \text{otherwise.}
\end{cases}
\]
Show that the exponential distribution has the so-called \emph{memoryless} property: for any $t>0$,
\[
\prob(X\leq x + t\,|\,X > t) = \prob(X \leq x)\quad\text{for all}\quad x\geq 0.
\]
\begin{answer}
For all $x>0$,
\begin{align*}
\prob(X > x + t\,|\, X > t)
	& =  \frac{\prob(X > x + t\text{ and } X > t)}{\prob(X > t)} \\
	& =  \frac{\prob(X > x + t)}{\prob(X > t)} \\
	& =  \frac{e^{-\lambda(x + t)}}{e^{-\lambda t}} =  e^{-\lambda x} = \prob(X > x).
\end{align*}
\end{answer}


%%==========================================================================
%% INFINITE EXPECTATION
%\question 
%Consider the following game. First a number $X$ is chosen uniformly at random from $[0,1]$, then a sequence $Y_1,Y_2,\ldots$ of numbers are chosen independently and uniformly at random from $[0,1]$. Let $Y_n$ be the first number in the sequence for which $Y_n > X$. When this occurs, the game stops and the player is paid $(n-1)$ pounds. Show that the expected win is infinite.
%\begin{answer}
%Let $Z$ represent the amount won. Suppose first that $X$ takes the value $x\in[0,1]$.
%\begin{align*}
%\prob(Z=k|X=x)
%	& = \prob(Y_1\leq x, Y_2\leq x, \ldots, Y_k\leq x, Y_{k+1}>x) \\
%	& = \prob(Y_1\leq x)\prob(Y_2\leq x)\ldots \prob(Y_k\leq x)\prob(Y_{k+1}>x) \qquad\text{(by independence)}\\
%	& = x^k(1-x)
%\end{align*}
%The PDF of $X$ is $f(x)=1$ for $x\in[0,1]$ and zero otherwise. Hence, by the law of total probability,
%\begin{align*}
%\prob(Z=k)
%	& = \int_0^1 \prob(Z=k|X=x) f(x)\,dx \\
%	& = \int_0^1 x^k(1-x)\,dx \\
%	& = \left[\frac{1}{k+1}x^{k+1}-\frac{1}{k+2}x^{k+2}\right]_0^1 \\
%	& = \frac{1}{k+1} - \frac{1}{k+2} \\
%	& = \frac{1}{(k+1)(k+2)} \\
%\end{align*}
%For all $k\geq 1$ we have $k+1\leq 2k$ and $k+2\leq 3k$ so
%\[
%\frac{1}{(k+1)(k+2)} \geq \frac{1}{6k^2}
%\]
%Thus $\expe(Z)$ satisfies
%\[
%\expe(Z) = \sum_{k=0}^{\infty}k\left(\frac{1}{(k+1)(k+2)}\right) \geq \frac{1}{6}\sum_{k=1}^{\infty}\frac{1}{k} = \infty,
%\]
%so the expected win is infinite.
%\end{answer} 


\end{questions}
\end{exercise}

%======================================================================
\endinput
%======================================================================
