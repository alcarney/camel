% !TEX root = main.tex
%======================================================================
\chapter{Expectation}\label{chap:expe}
%======================================================================

%----------------------------------------------------------------------
%\section{Motivation}
%----------------------------------------------------------------------

% centre of mass
\subsection*{Classical mechanics}
Consider a system of $n$ point particles with masses $m_1,m_2,\ldots,m_n$ placed at locations $x_1,x_2,\ldots,x_n$ along a thin rod. 
The point at which the rod balances is called the \emph{centre of mass} of the system.

\bigskip
The centre of mass is the point $\mu$ for which
\[
\sum_{i=1}^n (x_i-\mu)m_i = 0.
\]
Solving this equation for $\mu$, we obtain
\[
\mu = \frac{1}{M}\sum_{i=1}^n x_im_i\qquad\text{where}\qquad M = \sum_{i=1}^n m_i \text{ is the total mass}.
\]

\bit
\it $\mu$ is a single number that describes the \emph{location} of the system.
\it $\mu$ says nothing about the \emph{size} or \emph{shape} of the system.
\eit
	
\subsection*{Probability theory}
Let $(\Omega,\prob)$ be a finite probability space, let $X:\Omega\to\R$ be a random variable on $\Omega$, and let $\{x_1,x_2,\ldots,x_n\}$ be the range of $X$.
The PMF of $X$ is the function
\[
f(x_i) = \prob(X=x_i).
\]

The ``centre of mass'' of the random variable $X$ is the value $\mu$ for which
\[
\sum_{i=1}^n (x_i-\mu)f(x_i) = 0.
\]
Solving for $\mu$ and using the fact that $\sum_{i=1}^n f(x_i) = 1$, we obtain
\[
\mu = \sum_{i=1}^n x_i f(x_i).
\]

\bit
\it $\mu$ is called \emph{expected value} or \emph{expectation} of $X$.
\it $\mu$ describes the \emph{centre} or \emph{location} of the system.
\eit

%----------------------------------------------------------------------
\section{Expectation}
%----------------------------------------------------------------------
Let $(\Omega,\prob)$ be a finite probability space, let $p:\Omega\to[0,1]$ be the associated probability mass function, and let $X:\Omega\to\R$ be a random variable on $\Omega$. 

\begin{definition}\label{def:expectation}
The \emph{expectation} of $X$ is defined to be
\[
\expe(X) = \sum_{\omega\in\Omega} X(\omega)p(\omega).
\]
\end{definition}

\begin{theorem}[Expectation of Indicator Variables]
Let $I_A:\Omega\to\R$ be the indicator variable of event $A$. Then $\expe(I_A) = \prob(A)$.
\end{theorem}

\begin{proof}
$I_A(\omega)=1$ if $\omega\in A$, and $I_A(\omega)=0$ if $\omega\notin A$, so
\[
\expe(I_A) 
	= \sum_{\omega\in\Omega} I(\omega)p(\omega) 
	= \sum_{\omega\in A} 1\times p(\omega) + \sum_{\omega\notin A} 0\times p(\omega) 
	= \sum_{\omega\in A} p(\omega) 
	= \prob(A)
\]
\qed
\end{proof}

%----------------------------------------------------------------------
%\section{Expectation and the PMF}
%----------------------------------------------------------------------

\bit
\it In definition~\ref{def:expectation}, expectation is defined as a sum over the \emph{domain} of $X$.
\it Expectation can also be defined as a sum over the \emph{range} of $X$:
\eit

% theorem
\begin{theorem}\label{thm:expe_pmf}
Let $\{x_1,x_2,\ldots,x_n\}$ be the range of $X$, and let $f(x)$ denote its PMF. The expectation of $X$ can be written as 
\[
\expe(X) = \sum_{i=1}^n x_i f(x_i) 
\]
\end{theorem}

% proof
\begin{proof}
\bit
\it Let $A_i = \{\omega: X(\omega) = x_i\}$ for $i=1,2,\ldots,n$.
\it Each outcome $\omega\in\Omega$ belongs to exactly one of the sets $A_1,A_2,\ldots,A_n$.
\it The sets $A_1,\ldots,A_n$ thus form a partition of the sample space $\Omega$.
\eit
Consequently, 
\begin{align*}
\expe(X) 
	& = \sum_{\omega\in\Omega} X(\omega)p(\omega) \\
	& = \sum_{\omega\in A_1} X(\omega)p(\omega) + \sum_{\omega\in A_2} X(\omega)p(\omega) + \ldots + \sum_{\omega\in A_n} X(\omega)p(\omega) \\
	& = x_1\sum_{\omega\in A_1}p(\omega) + x_2\sum_{\omega\in A_2} p(\omega) + \ldots + x_n\sum_{\omega\in A_n} p(\omega) \\
	& = x_1\prob(A_1) + x_2\prob(A_2) + \ldots + x_n\prob(A_n) \\[1ex]
	& = x_1\prob(X=x_1) + x_2\prob(X=x_2) + \ldots + x_n\prob(X=x_n) \\
	& = \sum_{i=1}^n x_i \prob(X=x_i)
	= \sum_{i=1}^n x_i f(x_i).
\end{align*}
\qed
\end{proof}

% example
\begin{example}
Three fair dice are rolled independently. In return for a \pounds 1 stake, a player wins \pounds 1 if two of the dice show the same number and \pounds 5 if all three show the same number; otherwise the player loses the stake. Find the expected amount won by the player.
% solution
\begin{solution}
Let $X$ denote the amount won. The range of $X$ is the set $\{-1,1,5\}$.
\bit
\it There are $6^3 = 216$ possible outcomes, each of equal probability $1/216$.
\it $\{X=5\}$ is the event that all dice show the same number.
\par This can occur in six different ways so $\prob(X=5) = 6/216 = 1/36$.
\it $\{X=1\}$ is the event that exactly two of the dice show the same number.
\par This can occur in $90$ different ways so $\prob(X=1) = 90/216 = 15/36$.
\it $\{X=-1\}$ is the event that the dice all show different numbers.
\par This can occur in $120$ different ways so $\prob(X=1) = 120/216 = 20/36.$
\eit

The expected amount won is therefore
\[
\expe(X) = \sum_{x\in\{-1,1,5\}} x\prob(X=x)
	= \left(-1\times\frac{20}{36}\right) +\left(1\times\frac{15}{36}\right) +\left(5\times\frac{1}{36}\right) 
	= 0.
\]
Games in which the expected amount won (or lost) is zero are called \emph{fair} games.
\end{solution}
\end{example}


%----------------------------------------------------------------------
\section{Properties of expectation}
%----------------------------------------------------------------------
\begin{theorem}[Properties of expectation]\label{thm:prop_expe}
Let $\Omega$ be a finite sample space, and let $X,Y:\Omega\to\R$ be random variables on $\Omega$.
\ben
\it \textbf{Positivity}. 	If $X(\omega)\geq 0$ for all $\omega\in\Omega$, then $\expe(X)\geq 0$.
\it \textbf{Linearity}.		For all $a,b\in\R$, $\expe(aX+bY) = a\expe(X) + b\expe(Y)$.
\it \textbf{Monotonicity}.	If $X(\omega)\leq Y(\omega)$ for all $\omega\in\Omega$, then $\expe(X)\leq\expe(Y)$.
\een
\end{theorem}


\begin{proof}
\ben
\it % positivity
\textbf{Positivity}\par
If $X(\omega)\geq 0$ for all $\omega$, then $\expe(X)=\sum_{\omega\in\Omega}X(\omega)p(\omega)$ is a sum of positive terms, so $\expe(X)\geq 0$.

\it % linearity
\textbf{Linearity}\par
Let $a,b\in\R$. Because $\Omega$ is finite, the composite function $aX+bY$ is also a random variable on $\Omega$. We need to show that
\[
\expe(aX + bY)= a\expe(X)+b\expe(Y).
\]

\bit
\it Let $X$ take values in the range $\{x_1,x_2,\ldots,x_m\}$, and let $A_i = \{\omega: X(\omega)=x_i\}$.
\it Let $Y$ take values in the range $\{y_1,y_2,\ldots,y_n\}$, and let $B_j = \{\omega: Y(\omega)=y_j\}$.
\eit

The sets $\{A_i\cap B_j : i=1,2,\ldots,m ; j=1,2,\ldots,n\}$ form a partition of $\Omega$.
\bit
\it The random variable $aX + bY$ takes the value $ax_i + by_j$ for all $\omega\in A_i\cap B_j$.
\eit
By Theorem~\ref{thm:expe_pmf},
\begin{align*}
\expe(aX + bY) 
	& = \sum_{i=1}^{m}\sum_{j=1}^{n} (ax_i + by_j) \prob(A_i\cap B_j) \\
	& = a\sum_{i=1}^{m} x_i \sum_{j=1}^{n}\prob(A_i\cap B_j) + b\sum_{j=1}^{n} y_j \sum_{i=1}^{m} \prob(A_i\cap B_j) \\ 
\end{align*}
Furthermore,
\bit
\it $\{A_i\cap B_j\}_{j=1}^n$ is a partition of $A_i$, so $\sum_{j=1}^{n}\prob(A_i\cap B_j) = \prob(A_i)$.
\it $\{A_i\cap B_j\}_{i=1}^m$ is a partition of $B_j$, so $\sum_{i=1}^{m}\prob(A_i\cap B_j) = \prob(B_j)$.
\eit
Hence
\[
\expe(aX+bY) 
	= a\sum_{i=1}^{m} x_i\prob(A_i) + b\sum_{j=1}^{n} y_j\prob(B_j)
	= a\expe(X) + b\expe(Y)
\]
as required.

\it % monotonicity
\textbf{Monotonicity}\par
$X\leq Y$ if and only if $Y-X\geq 0$. 
	\bit
	\it By positivity, $\expe(Y-X)\geq 0$.
	\it By linearity, $\expe(Y)-\expe(X)\geq 0$, so $\expe(X)\leq\expe(Y)$.
	\eit
\een
\end{proof}

%----------------------------------------------------------------------
\section{The sample mean}
%----------------------------------------------------------------------
Consider a random experiment with a finite sample space $\Omega$. Let $X$ be a random variable on $\Omega$, and let $\{x_1,x_2,\ldots,x_n\}$ be the range of $X$.
\bit 
\it Suppose the random experiment is repeated $N$ times.
\it Let $z_1,z_2,\ldots,z_N$ be the sequence of observed values.
\it Let $N_i$ be the number of trials in which the observed value is $x_i$ (for $i=1,2,\ldots,n\}$
\eit
In common parlance, the ``average value'' of the observations is
\begin{hidebox}
\begin{align*}
\bar{z} 
	& = \frac{1}{N}\sum_{j=1}^N z_j \\
	& = \frac{1}{N}\sum_{i=1}^n x_i N_i \quad\text{because exactly $N_i$ of the observations are equal to $x_i$,} \\
	& = \sum_{i=1}^n x_i\left(\frac{N_i}{N}\right).
\end{align*}
\end{hidebox}
Under the frequentist model, the relative frequencies $N_i/N$ tend to the corresponding ``true'' probabilities $\prob(X=x_i)$ as the number of repetitions $N\to\infty$.
\bit
\it The ``average value'' $\bar{z}$ is called the \emph{sample mean}.
\it The sample mean is an empirical estimate of the expected value, $\expe(X)$.
\it The estimate becomes more accurate as the number of repetitions increases.
\eit

%----------------------------------------------------------------------
\section{Exercises}
\input{ex09_expectation}
%----------------------------------------------------------------------

%======================================================================
\endinput
%======================================================================
