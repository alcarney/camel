\documentclass[lecture]{csm}

% set meta information
\modulecode{MA1500}
\moduletitle{Introduction to Probability Theory}
\academicyear{2013/14}
\doctype{Lecture}
\doctitle{Discrete Probability}
\docnumber{14}

% local
\newcommand{\prob}{\mathbb{P}}
\newcommand{\expe}{\mathbb{E}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\def\it{\item}
\def\bit{\begin{itemize}}
\def\eit{\end{itemize}} 
\def\ben{\begin{enumerate}}
\def\een{\end{enumerate}}

%======================================================================
\begin{document}
\maketitle
\tableofcontents
%======================================================================


%----------------------------------------------------------------------
\section{Discrete probability spaces}
%----------------------------------------------------------------------

% definition: discrete probability spaces 
\begin{definition}
%Let $\Omega=\{\omega_1,\omega_2,\ldots\}$ be a countable sample space, and let $\mathcal{P}(\Omega)$ denote its power set.
Let $\Omega$ be a countable sample space, and let $\mathcal{P}(\Omega)$ denote its power set.
\ben
\it % 1
A \emph{probability mass function} on $\Omega$ is a function $p:\Omega\to[0,1]$
%\[
%\begin{array}{ccccc}
%p 	& :	& \Omega		& \to 		& [0,1] \\
%	&	& \omega		& \mapsto	& p(\omega),
%\end{array}
%\]
such that $\displaystyle\sum_{\omega\in\Omega} p(\omega) = 1$.
%such that $\displaystyle\sum_{i=1}^{\infty} p(\omega_i) = 1$.
\it % 2
A \emph{probability measure} on $\Omega$ is a function 
\[
\begin{array}{ccccl}
\prob 	& :	& \mathcal{P}(\Omega)	& \to 		& [0,1] \\[1ex]
		&	& A						& \mapsto	& \displaystyle\sum_{\omega\in A} p(\omega)
\end{array}
\]
where $p(\omega)$ is a probability mass function on $\Omega$.
\it % 3
The pair $(\Omega,\prob)$ is called a \emph{discrete probability space} on $\Omega$.
\een
\end{definition}

\begin{remark}
Finite sets are countable, so finite probability spaces are also discrete probabilty spaces.
\end{remark}

%----------------------------------------------------------------------
\newpage
\section{Discrete random variables}
%----------------------------------------------------------------------

% defin: simple & discrete random variables
\begin{definition}
Let $(\Omega,\prob)$ be a discrete probability space. A random variable $X:\Omega\to\R$ is called
\ben
\it \emph{simple} if it can take only a finite number of distinct values, and 
\it \emph{discrete} if it can take at most a countable number of distinct values.
\een
\end{definition}

% remark
\begin{remark}
\bit
\it Finite sets are countable, so simple random variables are also discrete random variables.
\it Any random variable on a finite probability space must be a simple random variable.
\it Any random variable on a discrete probability space must be a discrete random variable.
\eit
\end{remark}

\newpage

% defn: PMF
\begin{definition}
Let $(\Omega,\prob)$ be a discrete probability space. The \emph{probability mass function} (PMF) of a discrete random variable $X:\Omega\to\R$ is the function
\[
\begin{array}{cccl}
p:	& \mathbb{R}	& \longrightarrow	& [0,1] \\
	& x 			& \mapsto			& \prob(X = x).
\end{array}
\]
Note that $p(x)\neq 0$ for at most countably many $x\in\R$.
\end{definition}

Let $\{x_1,x_2,x_3,\ldots\}$ be the set of values taken by a discrete random variable $X:\Omega\to\R$, and define $p_k=\prob(X=x_k)$. By definition,
\[
\sum_{k=1}^{\infty} p_k = 1.
\]

Let $a_1,a_1,a_2,\ldots$ be an infinite sequence of non-negative real numbers, with $\sum_{k=0}^{\infty} a_k < \infty$.
\bit
\it Let $p_k = a_k/\sum_{k=0}^{\infty} a_k$.
\it Then $\sum_{k=0}^{\infty} p_k = 1$, so $p_1,p_2,p_3,\ldots$ defines the PMF of a discrete random variable.
\eit
\vspace*{2ex}
A number of discrete distributions can be constructed in this way.
%----------------------------------------------------------------------
\newpage
\section{Convergent Series}
%----------------------------------------------------------------------
Let $a_1,a_1,a_2,\ldots$ be an infinite sequence. The associated \emph{series} is the (ordered) sum of its terms:
\[
\sum_{k=0}^{\infty} a_k = a_0 + a_1 + a_2 + \ldots
\]

% defn: convergent series
\begin{definition}
\bit
\it A series $\sum_{k=0}^{\infty} a_k$ is said to \emph{converge} if the sequence of partial sums $\sum_{k=0}^{n}a_k$ converges to a finite limit as $n\to\infty$. 
\it Otherwise the series is said to \emph{diverge}.
\eit
\end{definition}

\begin{remark}
Loosely speaking, 
\bit
\it a series converges if $\sum_{k=0}^{\infty} a_k < \infty$, and %diverges  if $\sum_{k=0}^{\infty} a_k = \infty$.
\it a series diverges  if $\sum_{k=0}^{\infty} a_k = \infty$.
\eit
\end{remark}
\newpage

\begin{example}[Examples of convergent series]
\mbox{}\par\vspace{-4ex}
\small
\bit
\it$\displaystyle\sum_{k=0}^{\infty} ar^k 					\ =\ a + ar + ar^2 + ar^3 + \ldots = \frac{a}{1-r} \text{\quad provided $|r|<1$}.$
\it$\displaystyle\sum_{k=1}^{\infty} \frac{1}{k^2}			\ =\ 1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \ldots = \frac{\pi^2}{6}.$
\it$\displaystyle\sum_{k=1}^{\infty} \frac{1}{k^4}			\ =\ 1 + \frac{1}{2^4} + \frac{1}{3^4} + \frac{1}{4^4} + \ldots = \frac{\pi^4}{90}.$
\it$\displaystyle\sum_{k=0}^{\infty} \frac{1}{2^k}			\ =\ 1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \ldots = 2.$
\it$\displaystyle\sum_{k=0}^{\infty} \frac{1}{k!}			\ =\ 1 + 1 + \frac{1}{2} + \frac{1}{6} + \frac{1}{24} + \ldots = e.$
\it$\displaystyle\sum_{k=0}^{\infty} \frac{\lambda^k}{k!} 	\ =\ 1 + \lambda + \frac{\lambda^2}{2} + \frac{\lambda^3}{6} + \frac{\lambda^4}{24} + \ldots = e^{\lambda} \text{\quad for all $\lambda\in\R$}.$
\eit
\normalsize
\end{example}
\vspace*{-2ex}
\begin{remark}
\bit
\it The first series yields the \emph{geometric distribution} (next lecture).
\it The last series yields the \emph{Poisson distribution} (next lecture).
\eit
\end{remark}
%
%Not all series are convergent.
%
%\begin{example}[Examples of divergent series]
%\begin{align*}
%\sum_{k=1}^{\infty} k		 		& = 1 + 2 + 3 + 4 + \ldots \\
%\sum_{k=1}^{\infty} \frac{1}{k} 		& = 1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \ldots (\text{This is called the \emph{harmonic series}}.) \\
%\sum_{p\text{ prime}} \frac{1}{p} 	& = \frac{1}{2} + \frac{1}{3} + \frac{1}{5} + \frac{1}{7} +  \ldots 
%\end{align*}
%\end{example}

%----------------------------------------------------------------------
\newpage
\section{Expectation}
%----------------------------------------------------------------------
The expectation of a discrete random variable is computed in much the same way that the expectation of a simple random variable is computed, the only difference being that finite sums are replaced by infinite sums.

\begin{definition}
Let $X:\Omega\to\R$ be a random variable on a discrete probability space $(\Omega,\prob)$. 
\par
The \emph{expectation} of $X$ is defined to be
\[
\expe(X) = \sum_{\omega\in\Omega} X(\omega)p(\omega).
\]
\end{definition}

\newpage

% theorem
\begin{theorem}
Let $X:\Omega\to\R$ be a discrete random variable, let $\{x_1,x_2,\ldots\}$ be the range of $X$, and let $p(x) = \prob(X=x)$ be the PMF of $X$.
Then
\[
\expe(X) = \sum_{k=1}^{\infty} x_k\,\prob(X=x_k).
\]
and for any function $g:\R\to\R$,
\[
\expe\big[g(X)\big] = \sum_{k=1}^{\infty} g(x_k)p(x_k).
\]
\end{theorem}


% proof
\begin{proof}
See Exercises.
%To find $\prob\big(g(X)=y\big)$, we sum the probabilities $\prob(X=x)$ over all $x$ for which $g(x)=y$.
%\begin{align*}
%\expe\left(g(X)\right)
%	& = \sum_y y\,\prob\left(g(X)=y\right) \\
%	& = \sum_y y\sum_{\{x:g(x)=y\}}\prob(X=x) \\
%	& = \sum_y \sum_{\{x:g(x)=y\}}y\,\prob(X=x) \\
%	& = \sum_x g(x)\prob(X=x)
%\end{align*}
\end{proof}

%----------------------------------------------------------------------
\newpage
\section{Examples}
%----------------------------------------------------------------------

% example
\begin{example}
A coin has probability $p > 0$ of showing heads. The coin is tossed repeatedly until the first head occurs. Let $X$ be the number of times that the coin is tossed.
\bit
\it $X$ takes values in the set $\{1,2,3,4,5,\ldots\}$.
\it If we assume that the trials are independent, the PMF of $X$ is
\[
\prob(X=k) = (1-p)^{k-1}p\text{\qquad for\quad} k\in\{1,2,3,\ldots\}.
\]
\it The sum of these probabilities is equal to one:
\[
\sum_{k=1}^{\infty} \prob(X=k) = p\sum_{k=1}^{\infty} (1-p)^{k-1}  = \frac{p}{1-(1-p)} = 1.
\]
where we have used the formula for the sum of a geometric progression:% with $a = p$ and $r = (1-p)$:
\[
a + ar + ar^2 + \ldots = \frac{a}{1-r} \text{\qquad provided $|r|<1$},
\]
with $a = p$ and $r = (1-p)$.
%\it
%$X$ is said to have \emph{geometric distribution} with parameter $p$.

\eit

\end{example}

\newpage

% example
\begin{example}
Let $X$ be a discrete random variable, taking values in the set $\{1,2,\ldots\}$ with probabilities
\[
\prob(X=k) = \frac{90}{\pi^4 k^4}
\]

This is indeed a PDF because 
%$\displaystyle\sum_{k=0}^{\infty} \prob(X=k) = \frac{90}{\pi^4}\sum_{k=1}^{\infty}\frac{1}{k^4}$
%and
$\displaystyle\sum_{k=1}^{\infty} \frac{1}{k^4} = \frac{\pi^4}{90}$.


The expected value of $X$ is
\begin{align*}
\expe(X) 
	= \sum_{k=1}^{\infty} k \prob(X=k)
	= \frac{90}{\pi^4}\sum_{k=0}^{\infty}\frac{1}{k^3} 
%	= \zeta(3)/\zeta(4)
	\approx 1.1106.
\end{align*}

%\bit
%\it This is indeed a PDF on the set $\{0,1,2,\ldots\}$ because
%\[
%\sum_{k=0}^{\infty} \prob(X=k) = \frac{90}{\pi^4}\sum_{k=1}^{\infty}\frac{1}{k^4}
%\text{\qquad and\qquad}
%\sum_{k=0}^{\infty} \frac{1}{k^4} = \frac{\pi^4}{90}.
%\]
%\it The expected value of $X$ is
%\begin{align*}
%\expe(X) 
%	= \sum_{k=0}^{\infty} k \prob(X=k)
%	= \frac{90}{\pi^4}\sum_{k=0}^{\infty}\frac{1}{k^3} 
%%	= \zeta(3)/\zeta(4)
%	\approx 1.1106.
%\end{align*}
%\eit
\end{example}
\begin{remark}
The \emph{Riemann zeta function} is the function
$
\zeta(s) = \displaystyle\sum_{k=1}^{\infty}\frac{1}{k^s}
$
where $s\in\mathbb{R}$.
\bit
\it $\zeta(s)$ diverges for all $s\leq 1$
\it $\zeta(s)$ converges for all $s > 1$. 
\it In particular, $\zeta(2)=\pi^2/6$, $\zeta(3)\approx 1.2021$ and $\zeta(4)=\pi^4/90$.
\eit
\end{remark}
\newpage

% example
\begin{example}
Let $X$ be a discrete random variable, taking values in the set $\{1,2,\ldots\}$ with probabilities
\[
\prob(X=k) = \frac{6}{\pi^2 k^2}
\]

This is indeed a PDF because 
%$\displaystyle\sum_{k=0}^{\infty} \prob(X=k) = \frac{90}{\pi^4}\sum_{k=1}^{\infty}\frac{1}{k^4}$
%and
$\displaystyle\sum_{k=1}^{\infty} \frac{1}{k^2} = \frac{\pi^2}{6}$.

%This is indeed a PDF on the set $\{0,1,2,\ldots\}$, because
%\[
%\sum_{k=0}^{\infty} p_k = \frac{6}{\pi^2}\sum_{k=1}^{\infty}\frac{1}{k^2}
%\text{\quad and\quad}
%\sum_{k=0}^{\infty} \frac{1}{k^2} = \frac{\pi^2}{6}.
%\]
The expected value of $X$ is
\begin{align*}
\expe(X) 
	= \sum_{k=1}^{\infty} k \prob(X=k)
	= \frac{6}{\pi^2}\sum_{k=0}^{\infty}\frac{1}{k}.
%	= \zeta(1)/\zeta(2)
\end{align*}

\bit
\it The series $\displaystyle \zeta(1) = \sum_{k=0}^{\infty}\frac{1}{k}$ diverges.
\it This random variable has {infinite expectation}!
\eit
\end{example}
%======================================================================
\end{document}
%======================================================================
