\documentclass[lecture]{csm}

% set meta information
\modulecode{MA1500}
\moduletitle{Introduction to Probability Theory}
\academicyear{2013/14}
\doctype{Lecture}
\doctitle{The Uniform, Exponential and Normal Distributions}
\docnumber{19}

% local
\newcommand{\prob}{\mathbb{P}}
\newcommand{\expe}{\mathbb{E}}
\newcommand{\var}{\text{Var}}
\newcommand{\cov}{\text{Cov}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\def\it{\item}
\def\bit{\begin{itemize}}
\def\eit{\end{itemize}} 
\def\ben{\begin{enumerate}}
\def\een{\end{enumerate}}
\newcommand{\lt}{<}
\newcommand{\gt}{>}

%======================================================================
\begin{document}
\maketitle
\tableofcontents
%======================================================================

%----------------------------------------------------------------------
\section{The uniform distribution}
%----------------------------------------------------------------------
\begin{center}
\begin{tabular}{ll}\hline
Notation			& $X\sim\text{Uniform}[a,b]$ \\
Parameter(s)		& $a,b\in\R$, with $a<b$ \\
Range			& $[a,b]\subset\R$ \\
PDF				& $f(x) = \displaystyle\frac{1}{b-a}$ \\[2ex]
CDF				& $F(x) = \displaystyle\frac{x-a}{b-a}$ \\[2ex] \hline
\end{tabular}
\end{center}

% mean and variance
\subsubsection*{Mean and variance}
%As shown in Example~\ref{ex:continuous_uniform},
\[
\expe(X) = \frac{a+b}{2} \quad\text{and}\quad \var(X) = \frac{(b-a)^2}{12}
\]

\newpage

% example
\begin{example}
A string of length $L$ is cut at a point chosen uniformly at random along the string. Let $Y$ be the area of the rectangle, two of whose sides are formed by the two pieces of string. Find $\expe(Y)$, and the probability that $Y$ exceeds $5L^2/36$.
\end{example}
\begin{solution}
Let $X$ and $L-X$ denote the lengths of the two pieces. The area of the rectangle is $Y=X(L-X)$. Since $X$ has the uniform distribution of $[0,L]$, it has probability mass function
\[
f(x) = \begin{cases}
	\displaystyle\frac{1}{L}	& \text{if }\ 0\leq x\leq L, \\[2ex]
	0			& \text{otherwise}.	
\end{cases}
\]
Let $g(x)=x(L-x)$. The expected value of $Y=g(X)$ is
\begin{align*}
\expe(Y)
	= \int_{-\infty}^{\infty} g(x)f(x)\,dx 
	= \int_0^L x(L-x)\frac{1}{L}\,dx 
	= \frac{1}{L}\left[\frac{Lx^2}{2}-\frac{x^3}{3}\right]_0^L 
	= \frac{L^2}{6}.
\end{align*}
The probability that $Y=g(X)$ exceeds $5L^2/36$ is
\begin{align*}
\prob\left(Y>\frac{5L^2}{36}\right)	
	& = \prob\left(LX - X^2 > \frac{5L^2}{36}\right) \\
	& = \prob\left(X^2 - LX + \frac{5L^2}{36} < 0 \right) \\
	& = \prob\left[\left(X-\frac{5L}{6}\right)\left(X-\frac{L}{6}\right) < 0\right]
\end{align*}
\bit
\it The expression $\displaystyle\left(X-\frac{5L}{6}\right)\left(X-\frac{L}{6}\right) < 0$ iff exactly one of the factors is negative. 
\it This occurs if and only if $\displaystyle\frac{L}{6} < X < \frac{5L}{6}$.
\eit
Hence,
\[
\prob\left(Y>\frac{5L^2}{36}\right)
	= \prob\left(\frac{L}{6} < X < \frac{5L}{6}\right)
	= \int_{L/6}^{5L/6} \frac{1}{L}\,dx = \frac{2}{3}.
\]	
\end{solution}

%----------------------------------------------------------------------
\section{The negative exponential distribution}
%----------------------------------------------------------------------
\begin{center}
\begin{tabular}{ll}\hline
Notation			& $X\sim\text{Exponential}(\lambda)$ \\
Parameter(s)		& $\lambda>0$ \quad (rate) \\
Range			& $[0,\infty)$ \\
PDF				& $f(x) = \lambda e^{-\lambda x}$ \\
CDF				& $F(x) = 1 - e^{-\lambda x}$ \\ \hline
\end{tabular}
\end{center}

% mean and variance
\subsubsection*{Mean and variance}
%As shown in Example~\ref{ex:continuous_uniform},
%\[
%\expe(X) = \frac{1}{\lambda} \quad\text{and}\quad \var(X) = \frac{1}{\lambda^2}
%\]
To find the expected value of $X$,
\[
\expe(X) = \int xf(x)\,dx = \lambda\int_0^{\infty} xe^{-\lambda x}\,dx
\]
Integrating by parts,
\begin{equation*}\label{eq:expe_expo}
\int_0^{\infty} xe^{-\lambda x}\,dx
	= \left[-\frac{xe^{-\lambda x}}{\lambda}\right]_0^{\infty} + \int_0^{\infty} \frac{e^{\lambda x}}{\lambda}\,dx
	= 0 + \frac{1}{\lambda}\int_0^{\infty} e^{-\lambda x}\,dx
	= \frac{1}{\lambda}\left[-\frac{e^{-\lambda x}}{\lambda}\right]_0^{\infty}
	= \frac{1}{\lambda^2}.% \tag{*}
\end{equation*}
Hence, 
\[
\expe(X) = \lambda\int_0^{\infty} xe^{-\lambda x}\,dx = \frac{1}{\lambda}.
\]
To compute the variance, 
\[
\expe(X^2) = \int x^2 f(x)\,dx = \lambda\int_0^{\infty} x^2 e^{-\lambda x}\,dx
\]
Integrating by parts,
\[
\int_0^{\infty} x^2 e^{-\lambda x}\,dx
	= \left[x^2\left(-\frac{e^{-\lambda x}}{\lambda}\right)\right]_0^{\infty} + \int_0^\infty 2x\left(\frac{e^{-\lambda x}}{\lambda}\right)\,dx 
	= \frac{2}{\lambda}\int_0^{\infty} xe^{-\lambda x}\,dx 
	= \frac{2}{\lambda^3}.% \qquad \text{by Eq.~(\ref{eq:expe_expo}).}
\]
Hence 
\[
\expe(X^2) = \lambda\int_0^{\infty} x^2 e^{-\lambda x}\,dx = \frac{2}{\lambda^2},
\]
and the variance is 
\[
\var(X) = \expe(X^2) - \expe(X)^2 = \frac{2}{\lambda^2} - \left(\frac{1}{\lambda}\right)^2 = \frac{1}{\lambda^2}.
\]

% example
%\begin{example}
%Let $T$ be a random variable representing the time (in hours) before a new type of lightbulb fails. Suppose that $T$ has exponential distribution with parameter $\lambda=0.001$.
%\ben
%\it Find the mean and standard deviation of the lifetime of a ligtbulb.
%\it Calculate the probability that a lightbulb lasts for at least $500$ hours.
%\it Calculate the conditional probability that a lightbulb lasts for at least $500$ hours, given that it has lasted for $300$ hours.
%\een
%\end{example}

\newpage

\begin{example}
The lifetime of a type of electrical fuse has exponential distribution with a mean of $4$ years. 
\ben
\it Find the probability that a fuse lasts for at least $2$ years.
\it Find the probability that a fuse lasts for at least $6$ years, given that it lasts for at least $4$ years.
\een
\end{example}

\begin{solution}
Let $X$ be the lifetime of a fuse. Since the mean is $4$, the (rate) parameter of the distribution is $\lambda=1/4$, so $X$ has the distribution function 
\[
F(x) = \begin{cases}
	1 - e^{-x/4} 	& \text{if }\ x\geq 0, \\
	0				& \text{otherwise}.	
\end{cases}
\]
Thus $\prob(X\geq 2) = 1-\prob(X\leq 2) = 1-F(2) = 1 - (1 - e^{-2/4}) = e^{-1/2} = 0.6065$, and 
\[
\prob(X\geq 6\,|\,X\geq 4)
	= \frac{\prob(X\geq 6\text{ and } X\geq 4)}{\prob(X\geq 4)} 
	= \frac{\prob(X\geq 6)}{\prob(X\geq 4)}
	= \frac{e^{-6/4}}{e^{-4/4}} = e^{-1/2} = 0.6065 \quad\text{(again)}.
\]
This is an example of the `memoryless' property of the exponential distribution.
\end{solution}

The exponential distribution is related to the Poisson distribution: if the number of `arrivals' per unit time has Poisson distribution with mean $\lambda$, the inter-arrival times are independent random variable, each having exponential distribution with rate parameter $\lambda$. 

% example
\begin{example}
The number of customers entering a supermarket per minute has $\text{Poisson}(10)$ distribution.% with mean 10. 
\ben
\it What is the distribution function of the time between the arrival of successive customers?
\it What is the probability that a customer arrives between three and five seconds after the previous customer?
\een
\end{example}

\begin{solution}
\ben
\it % << (i)
Let $\lambda=10$ denote the mean number of customers arriving per minute, and let $T$ denote the time between successive arrivals. Then $T$ has exponential distribution with rate parameter $\lambda$, so its distribution function is
\[
F(t) = \begin{cases}
	1 - e^{-\lambda t}	& \text{if }\ t \geq 0 \\
	0					& \text{otherwise.}
\end{cases}
\]
\it % << (ii)
The probability that a customer arrives between 3 and 5 seconds after the previous customer is
\begin{align*}
\prob(3/60\leq T\leq 5/60) 
	& = F(5/60) - F(3/60) \\
	& = e^{-3\lambda/60} - e^{-5\lambda/60} \\
	& = e^{-1/2} - e^{-5/6} = 0.6065 - 0.4346 = 0.1719.
\end{align*}
\een
\end{solution}

%----------------------------------------------------------------------
\newpage
\section{The normal distribution}
%----------------------------------------------------------------------
\begin{center}
\begin{tabular}{ll}\hline
Notation			& $X\sim\text{N}(\mu,\sigma^2)$ \\
Parameter(s)		& $\mu\in\R$, $\sigma^2\in\R^{+}$ \\
Range			& $\R$ \\
PDF				& $f(x) = \displaystyle\frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}$ \\[2ex] \hline 
\end{tabular}
\end{center}

The normal distribution is based on the \emph{Gaussian integral}:
\[
\int_{-\infty}^{\infty} e^{-x^2}\,dx = \sqrt{\pi}
\]
For this reason, it is often called the \emph{Gaussian distribution}.

% standard normal distribution
\begin{definition}
The \emph{standard normal distribution} is the normal distribution with parameters $\mu=0$ and $\sigma^2=1$.
\end{definition}

\newpage

Let $Z\sim\text{N}(0,1)$ be a standard normal variable.
\ben
\it The distribution function of $Z$ is usually denoted by $\Phi(z) = \prob(Z\leq z)$.
\it The density function of $Z$ is usually denoted by $\phi(z)$:
\[
\phi(z) = \frac{1}{\sqrt{2\pi}} e^{-z^2/2}
\]
\een

% mean and variance
\subsubsection*{Mean and variance}
If $Z\sim\text{N}(0,1)$ then
\begin{align*}
\expe(Z) = \int_{-\infty}^{\infty} z \phi(z) \,dz 
	& = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty} z e^{-\frac{1}{2}z^2} \,dz \\
	& = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty} \frac{d}{dz}(-e^{-\frac{1}{2}z^2}) \,dz \\
	& = \frac{1}{\sqrt{2\pi}}\left[ -e^{-\frac{1}{2}z^2} \right]_{-\infty}^{\infty} \\
	& = 0. 
\end{align*}
and
\begin{align*}
\expe(Z^2) 
	= \int_{-\infty}^{\infty} z^2 \phi(z)\,dz 
	& = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty} z^2 e^{-z^2/2} \,dz \\
	& = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty} z\frac{d}{dz}(-e^{-z^2/2}) \,dz \\
	& = \frac{1}{\sqrt{2\pi}}\left[ -ze^{-z^2/2} \right]_{-\infty}^{\infty} + \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty} e^{-z^2/2}\,dz \qquad\text{(integration by parts)}\\
	& = 0 + \frac{1}{\sqrt{\pi}}\int_{-\infty}^{\infty} e^{-t^2}\,dt \qquad\text{(using a change of variable: $t=z\sqrt{2}$)} \\
	& = 1.
\end{align*}	
Thus $\var(Z) = \expe(Z^2) - \expe(Z)^2 = 1.$

\vspace*{2ex}
In general, let $X=\mu+\sigma Z$ where $Z\sim N(0,1)$. The distribution function of $X$ is 
\[
F(x) 
	= \prob(X\leq x) 
	= \prob\left(\mu + \sigma Z \leq x\right) 
	= \prob\left(Z\leq \frac{x-\mu}{\sigma}\right) 
	= \Phi\left(\frac{x-\mu}{\sigma}\right)
\]
and (using the chain rule), the density function of $X$ is
\begin{align*}
f(x) 
	& = \frac{d}{dx}F(x) \\
	& = \frac{d}{dx}\Phi\left(\frac{x-\mu}{\sigma}\right) \\
	& = \frac{1}{\sigma}\phi\left(\frac{x-\mu}{\sigma}\right) \\
	& = \frac{1}{\sigma\sqrt{2\pi}}\exp\left[{-\displaystyle\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}\right]
\end{align*}
so $X\sim\text{N}(\mu,\sigma^2)$. By the linearity of expectation, 
\begin{align*}
\expe(X)	& = \expe(\mu+\sigma Z) = \mu + \sigma\expe(Z) = \mu, \\
\intertext{and by the properties of variance}
\var(X)	& = \var(\mu+\sigma Z) = \sigma^2\var(Z) = \sigma^2.
\end{align*}

Hence the normal distribution is parameterized by its mean $\mu$ and variance $\sigma^2$.

\newpage

% example
\begin{example}
The height $X$ in metres of a randomly chosen adult male has a distribution which is approximately normal with mean $\mu$ and variance $\sigma^2$. If $10\%$ of males in the population have heights greater than $1.8$ metres, and $5\%$ have heights less than $1.6$ metres, find $\mu$ and $\sigma$. 

\vspace{2ex}
For $Z\sim\text{N}(0,1)$, you may assume that
\begin{align*}
\prob(Z\leq -1.645)	& \approx 0.05 \text{\quad and} \\
\prob(Z\leq 1.280)	& \approx 0.90.
\end{align*}
\bit
\it The values $z_{0.05} = -1.645$ and $z_{0.90} = 1.280$ are called the \emph{critical points} of the standard normal distribution at levels $0.05$ and $0.90$ respectively. 
\it Critical values can be looked up in statistical tables, or computed using a statistical software package.
\eit

%For $Z\sim\text{N}(0,1)$, you may assume that $\prob(Z\leq -1.645)\approx 0.05$ and $\prob(Z\leq 1.280)\approx 0.90$. 
%
%[The values $z_{0.05} = -1.645$ and $z_{0.90} = 1.280$ are the \emph{critical points} of the standard normal distribution at levels $0.05$ and $0.90$ respectively. These critical points would usually be looked up in statistical tables, or computed using a statistical software package.)]
\end{example}

\newpage

\begin{solution}
\bit
\it Let $X\sim\text{N}(\mu,\sigma^2)$. 
\eit
From the question, we know that $\prob(X\leq 1.6) = 0.05$ and $\prob(X\leq 1.8)=0.9$.
\bit
\it Let $Z=\displaystyle\frac{X-\mu}{\sigma}$. Then $Z$ has standard normal distribution, with%Then $Z\sim\text{N}(0,1)$, with
\eit
%\bit
%\it 
Then $Z\sim\text{N}(0,1)$, with
$\prob\left(Z\leq \displaystyle\frac{1.6-\mu}{\sigma}\right) = 0.05$ and
$\prob\left(Z\leq \displaystyle\frac{1.8-\mu}{\sigma}\right) = 0.90$.
%\eit

\vspace{2ex}
From the critical points given in the question,
\[
\displaystyle\frac{1.6-\mu}{\sigma} = -1.645 \text{\quad and\quad} \displaystyle\frac{1.8-\mu}{\sigma} = +1.280.
\]
%Thus we obtain $\mu - 1.645\sigma = 1.6$ and $\mu + 1.280\sigma = 1.8$. 
Solving these equations, we obtain
\[
\mu=1.712 \text{\quad and\quad} \sigma=0.0684.
\]
%Solving these equations, we obtain $\mu=1.712$ and $\sigma=0.0684$.

The height of adult males therefore has mean $1.712$m and standard deviation $0.068$m.
\end{solution}


%----------------------------------------------------------------------
\newpage
\section{The chi-squared distribution}
%----------------------------------------------------------------------
During an experiment, we make a sequence of independent observations $X_1,X_2,\ldots,X_n$. An expert tells us that our observations should be normally distributed with mean $\mu$ and variance $\sigma^2$. How can we test to see whether our data fits this model?

Under the proposed model, the standardised variables $\displaystyle Z_i = \frac{X_i-\mu}{\sigma}$ should have standard normal distribution $\text{N}(0,1)$. To quantify the extent to which our data fits the model, we compute the total squared deviation between our standardised observations $Z_1,Z_2,\ldots,Z_n$ and their hypothetical mean, which is zero. This is called the \emph{chi-squared} statistic:
\[
\chi^2_n = \sum_{i=1}^n Z_i^2 = \sum_{i=1}^n \left(\frac{X_i-\mu}{\sigma}\right)^2
\]
If the expert is correct, $\chi^2_n$ will have the so-called \emph{chi-squared} distribution with $n$ degrees of freedom. Consequently, if the observed value of $\chi^2_n$ is far from the centre of this distribution (i.e.\ the observed value is in the upper or lower tail of the distribution), we might conclude that the observations are \emph{not} normally distributed.

\begin{center}
\begin{tabular}{ll}\hline
Notation			& $X\sim\text{Chi-squared}(k)$ \\
Parameter(s)		& $k \in \N$ \quad (degrees of freedom) \\
Range			& $\R^{+}$ \\
PDF				& $f(x) = \displaystyle\frac{1}{2^{k/2}\Gamma(k/2)} x^{k/2-1} e^{-x/2}$ \\[2ex] \hline
\end{tabular}
\end{center}

Let $Z_1,Z_2,\ldots,Z_k$ be independent standard normal random variables, and let
%$Z_i\sim\text{N}(0,1)$, and let 
\[
\displaystyle X=\sum_{i=1}^k Z_i^2.
\]
%$ denote the sum of their squares.
%\[
%X = \sum_{i=1}^k Z_i^2.
%\]
Then $X$ is said to have \emph{chi-squared distribution} with $k$ degrees of freedom.

\newpage

% mean and variance
\subsubsection*{Mean and variance}
\begin{hidebox}
If $Z_i\sim\text{N}(0,1)$, then 
\[
\expe(Z_i^2) = \var(Z_i)+\expe(Z_i)^2 = 1.
\]
Thus by the linearity of expectation,
\[
\expe(X) = \expe(Z^2_1)+\expe(Z^2_2)+\ldots+\expe(Z^2_k) = k
\]

It is easy to show that $\expe(Z_i^4)=3$, so 
\[
\var(Z_i^2) = \expe(Z_i^4)-\expe(Z_i^2)^2 = 2.
\]
Thus, because the $Z_i$ are independent,
\[
\var(X) = \var(Z^2_1)+\var(Z^2_2)+\ldots+\var(Z^2_k) = 2k.
\]
\end{hidebox}

%======================================================================
\end{document}
%======================================================================
