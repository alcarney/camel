\documentclass[lecture]{csm}
%\documentclass[blanks,lecture]{csm}

% set meta information
\modulecode{MA1500}
\moduletitle{Introduction to Probability Theory}
\academicyear{2013/14}
\doctype{Lecture}
\doctitle{Expectation}
\docnumber{7}

% local
\newcommand{\R}{\mathbb{R}}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\expe}{\mathbb{E}}
\def\it{\item}
\def\bit{\begin{itemize}}
\def\eit{\end{itemize}} 
\def\ben{\begin{enumerate}}
\def\een{\end{enumerate}}

%======================================================================
\begin{document}
\maketitle
\tableofcontents
%======================================================================

\subsection*{Classical mechanics}
Consider a system of $n$ point particles with masses $m_1,m_2,\ldots,m_n$ placed at locations $x_1,x_2,\ldots,x_n$ along a thin rod. 
\bit
\it The point at which the rod balances is called the \emph{centre of mass} of the system.
\eit
The centre of mass is defined to be the point $\mu$ for which
\[
\sum_{i=1}^n (x_i-\mu)m_i = 0.
\]
Solving this equation for $\mu$, we obtain
\[
\mu = \frac{1}{M}\sum_{i=1}^n x_im_i\qquad\text{where}\qquad M = \sum_{i=1}^n m_i.
\]

\bit
\it The centre of mass $\mu$ is a single number that describes the \emph{location} of the system.
\it $\mu$ says nothing about the \emph{size} or \emph{shape} of the system.
\eit
	
\break % <<

\subsection*{Probability theory}
Let $\Omega$ be a finite sample space, and let $X:\Omega\to\R$ be a random variable on $\Omega$.
\bit
\it Suppose that $X$ takes values in the set $\{x_1,x_2,\ldots,x_n\}\subset\R$.
\it Let $p_k$ be the probability that $X$ takes the value $x_k$.
\[
p_k = \prob(X=x_k) = \sum_{\omega:X(\omega)=x_k} p(\omega).
\]
\eit

The ``centre of mass'' of the random variable $X$ is the value $\mu$ for which
\[
\sum_{k=1}^n (x_k-\mu)p_k = 0.
\]
Solving for $\mu$ and using the fact that $\sum_{k=1}^n p_k = 1$, we obtain
\[
\mu = \sum_{k=1}^n x_k p_k.
\quad
\]

The centre of mass of a random variable is called its \emph{expected value} or \emph{expectation}.

%----------------------------------------------------------------------
\section{Expectation of a random variable}
%----------------------------------------------------------------------
\begin{definition}
Let $X:\Omega\to\R$ be a random variable on a finite probability space $(\Omega,\prob)$. The \emph{expectation} of $X$ is defined to be
\[
\expe(X) = \sum_{\omega\in\Omega} X(\omega)p(\omega).
\]
where $p(\omega)$ is the probability of outcome $\omega$.
\end{definition}

\begin{theorem}[Expectation of Indicator Variables]
Let $I_A:\Omega\to\R$ be the indicator variable of event $A$. Then $\expe(I_A) = \prob(A)$.
\end{theorem}
\begin{proof}
$I_A(\omega)=1$ if $\omega\in A$, and $I_A(\omega)=0$ if $\omega\notin A$, so
\[
\expe(I_A) 
	= \sum_{\omega\in\Omega} I(\omega)p(\omega) 
	= \sum_{\omega\in A} 1\times p(\omega) + \sum_{\omega\notin A} 0\times p(\omega) 
	= \sum_{\omega\in A} p(\omega) 
	= \prob(A)
\]
\qed
\end{proof}

%----------------------------------------------------------------------
\section{Expectation and the PMF}
%----------------------------------------------------------------------
The expectation $\expe(X)=\sum_{\omega\in\Omega} X(\omega)p(\omega)$, where $p(\omega)$ is the probability that outcome $\omega\in\Omega$ occurs, can also be expressed as the sum 
\[
\expe(X) = \sum_{x\in\R} x\,p(x),
\] 
where $p(x)$ is the probability that $X$ takes the value $x\in\R$.

\bit
\it The former is a sum over the \emph{domain} of $X$. %, i.e.\ the sample space $\Omega$.
\it The latter is a sum over the \emph{range} of $X$. %, i.e. the set % $X(\Omega)=\{x\in\R: X(\omega)=x\text{ for some }\omega\in\Omega\}$
\it Note that if $\Omega$ is finite, the range of $X$ must also be finite.
% (i.e. $X$ can only take finitely many distinct values).
\eit

% theorem
\begin{theorem}
Let $(\Omega,\prob)$ be a finite probability space, let $X:\Omega\to\R$ be a random variable on $\Omega$, let $\{x_1,x_2,\ldots,x_n\}$ denote the range of $X$, and let $p_k =\prob(X=x_k)$ denote the PMF of $X$. Then
\[
\expe(X) = \sum_{k=1}^n x_k p_k = \sum_{k=1}^n x_k\,\prob(X=x_k) 
\]
\end{theorem}

\break % <<

% proof
\begin{proof}
\bit
\it Let $A_k = \{X=x_k\} = \{\omega: X(\omega) = x_k\}$.
\it Each outcome $\omega\in\Omega$ belongs to exactly one of the sets $A_1,A_2,\ldots,A_n$.
\it Hence the collection $\{A_1,\ldots,A_n\}$ is a partition of the sample space $\Omega$, so.
\eit
\begin{align*}
\expe(X) 
	& = \sum_{\omega\in\Omega} X(\omega)p(\omega) \\
	& = \sum_{\omega\in A_1} X(\omega)p(\omega) + \sum_{\omega\in A_2} X(\omega)p(\omega) + \ldots + \sum_{\omega\in A_n} X(\omega)p(\omega) \\
	& = x_1\sum_{\omega\in A_1}p(\omega) + x_2\sum_{\omega\in A_2} p(\omega) + \ldots + x_n\sum_{\omega\in A_n} p(\omega) \\
	& = x_1\prob(A_1) + x_2\prob(A_2) + \ldots + x_n\prob(A_n) \\[1ex]
	& = x_1\prob(X=x_1) + x_2\prob(X=x_2) + \ldots + x_n\prob(X=x_n) \\
	& = \sum_{k=1}^n x_kp_k.
\end{align*}
\qed
\end{proof}

\break % << 

% example
\begin{example}
Three fair dice are rolled independently. In return for a \pounds 1 stake, a player wins \pounds 1 if two of the dice show the same number and \pounds 5 if all three show the same number; otherwise the player loses the stake. Find the expected amount won.
% solution
\begin{solution}
Let $X$ denote the amount won. The range of $X$ is the set $\{-1,1,5\}$.
\bit
\it There are $6^3 = 216$ possible outcomes, each of equal probability $1/216$.
\it $X=5$ is the event that all dice show the same number.
\par This can occur in six different ways so $\prob(X=5) = 6/216 = 1/36$.
\it $X=1$ is the event that exactly two of the dice show the same number.
\par This can occur in $90$ different ways so $\prob(X=1) = 90/216 = 15/36$.
\it $X=-1$ is the event that the dice all show different numbers.
\par This can occur in $120$ different ways so $\prob(X=1_ = 120/216 = 20/36.$
\eit
%The expected amount won is therefore
\[
\expe(X) = \sum_{x\in X(\Omega)} x\prob(X=x)
	= \left(-1\times\frac{20}{36}\right) +\left(1\times\frac{15}{36}\right) +\left(5\times\frac{1}{36}\right) 
	= 0.
\]
Games in which the expected amount won (or lost) is zero are called \emph{fair} games.
\end{solution}
\end{example}


%----------------------------------------------------------------------
\section{Properties of expectation}
%----------------------------------------------------------------------
\begin{definition}
\ben
\it A real-valued function $f:A\to\R$ is called \emph{non-negative} if $f(a)\geq 0$ for all $a\in A$.
\it $f:A\to\R$ is said to \emph{dominate} $g:A\to\R$ if $f(a)\geq g(a)$ for all $a\in A$.
\een
In particular,
\bit
\it A random variable $X:\Omega\to\R$ is called \emph{non-negative} if $X(\omega)\geq 0$ for all $\omega\in\Omega$, and
\it if $X,Y:\Omega\to\R$ are such that $X(\omega)\geq Y(\omega)$ for all $\omega\in\Omega$, this is denoted by $X\geq Y$.
\eit
\end{definition}

\begin{theorem}[Properties of expectation]
Let $X,Y:\Omega\to\R$ be random variables on a finite probability space.
\ben
\it\textbf{Linearity}.
$\expe(aX+bY) = a\expe(X) + b\expe(Y)$ for all $a,b\in\R$.
\it\textbf{Positivity}. 
If $X\geq 0$ then $\expe(X)\geq 0$.
\it\textbf{Monotonicity}.
If $X\geq Y$ then $\expe(X)\geq\expe(Y)$.
\een
\end{theorem}

\break % <<

\begin{proof}
\ben
\it\textbf{Linearity}\par
Let $a,b\in\R$ and $Z=aX+bY$. Then $Z:\Omega\to\R$ is also a random variable. We need to show that
\[
\expe(Z)=\sum_{\omega\in\Omega} Z(\omega)p(\omega) = a\expe(X)+b\expe(Y).
\]
\bit
\it Let $X$ take values in the set $\{x_1,x_2,\ldots,x_m\}$, and define $A_i = \{X=x_i\}$.
\it Let $Y$ take values in the set $\{y_1,y_2,\ldots,y_n\}$, and define $B_j = \{Y=y_j\}$.
\eit

The collection of sets $\{A_i\cap B_j\}{_{i=1}^m},{_{j=1}^n}$ is a partition of $\Omega$.
\bit
\it Note that $\{A_i\cap B_j\}{_{j=1}^n}$ is a partition of $A_i$: $\sum_{j=1}^{n}\prob(A_i\cap B_j) = \prob(A_i)$.
\it Note that $\{A_i\cap B_j\}{_{i=1}^m}$ is a partition of $B_j$: $\sum_{i=1}^{m}\prob(A_i\cap B_j) = \prob(B_j)$.
\eit
\break % <<
For every fixed set $A_i\cap B_j$ in the partition, $Z(\omega) = ax_i + by_j$ for all $\omega\in A_i\cap B_j$.
\begin{align*}
\expe(Z) = \sum_{\omega\in\Omega} Z(\omega)p(\omega)
%	& = \sum_{\omega\in\Omega} (aX(\omega)+bY(\omega))\prob(\omega) \\
	& = \sum_{i=1}^{m}\sum_{j=1}^{n} (ax_i + by_j) \prob(A_i\cap B_j) \\
	& = a\sum_{i=1}^{m} x_i \sum_{j=1}^{n}\prob(A_i\cap B_j) + b\sum_{j=1}^{n} y_j \sum_{i=1}^{m} \prob(A_i\cap B_j) \\ 
	& = a\sum_{i=1}^{m} x_i\prob(A_i) + b\sum_{j=1}^{n} y_j\prob(B_j) \\
	& = a\expe(X) + b\expe(Y).
\end{align*}
\it\textbf{Positivity}\par
If $X\geq 0$ then $\expe(X)=\sum_{\omega\in\Omega}X(\omega)p(\omega)$ is a sum of positive terms, so $\expe(X)\geq 0$.
\it\textbf{Monotonicity}\par
$X\geq Y$ if and only if $X-Y\geq 0$. By positivity we have $\expe(X-Y)\geq 0$, so by linearity it follows that $\expe(X)\geq\expe(Y)$.
\een
\end{proof}

%----------------------------------------------------------------------
\section{The sample mean}
%----------------------------------------------------------------------
Let $\Omega$ be a finite sample space, and let $X:\Omega\to\R$ be a random variable taking values in the set $\{a_1,a_2,\ldots,a_n\}$.
\bit 
\it The random experiment is repeated $N$ times.
\it Let $x_1,x_2,\ldots,x_N$ be the sequence of values taken by $X$.
\it Let $N_k$ be the number of trials in which the observed value is $a_k$.
\eit
The \emph{sample mean} (or \emph{average value}) of the observations is
\[
\bar{x} = \frac{1}{N}\sum_{j=1}^N x_j = \frac{1}{N}\sum_{k=1}^n a_k N_k = \sum_{k=1}^n a_k\left[\frac{N_k}{N}\right].
\]

Under the frequentist model, the relative frequencies $N_k/N$ tend to the associated ``true'' probabilities $\prob(X=a_k)$ as the number of repetitions $N\to\infty$.
\bit
\it The sample mean $\bar{x}$ is an empirical estimate of the ``true'' mean, $\expe(X)$.
\it The estimate becomes more accurate as the number of repetitions increases.
\eit


%======================================================================
\end{document}
%======================================================================
